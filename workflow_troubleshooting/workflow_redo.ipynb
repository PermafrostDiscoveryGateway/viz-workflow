{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsl Workflow with Ingmar's lake Change Sample Data \n",
    "\n",
    "- gpkg files\n",
    "- new TMS to work with GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# PDG packages\n",
    "import pdgstaging\n",
    "import pdgraster\n",
    "#import py3dtiles\n",
    "#import viz_3dtiles\n",
    "#from viz_3dtiles import TreeGenerator, BoundingVolumeRegion\n",
    "#import pdgpy3dtiles\n",
    "#from StagedTo3DConverter import StagedTo3DConverter\n",
    "\n",
    "# logging and configuration\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import logging.config\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "# Parsl\n",
    "import parsl\n",
    "from parsl import python_app\n",
    "from parsl.config import Config\n",
    "from parsl.channels import LocalChannel\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.providers import LocalProvider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Note: Robyn figured out that using TMS WGS1984Quad instead of WorldCRS84Quad fixes the geopandas issue. This \"new\" TMS is specified in the config.\\\n",
    "Config sourced in for this workflow: `ingmar_config.json`\n",
    "\n",
    "```\n",
    "{\n",
    "    \"simplify_tolerance\": 0.0001,\n",
    "    \"tms_id\": \"WGS1984Quad\",\n",
    "    \"z_range\": [0, 11],\n",
    "    \"statistics\": [\n",
    "        {\n",
    "            \"name\": \"polygon_count\",\n",
    "            \"weight_by\": \"count\",\n",
    "            \"property\": \"centroids_per_pixel\",\n",
    "            \"aggregation_method\": \"sum\",\n",
    "            \"resampling_method\": \"sum\",\n",
    "            \"val_range\": [0, null],\n",
    "            \"nodata_val\": 0,\n",
    "            \"nodata_color\": \"#ffffff00\",\n",
    "            \"palette\": [\"#d9c43f\", \"#d93fce\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"coverage\",\n",
    "            \"weight_by\": \"area\",\n",
    "            \"property\": \"area_per_pixel_area\",\n",
    "            \"aggregation_method\": \"sum\",\n",
    "            \"resampling_method\": \"average\",\n",
    "            \"val_range\": [0, 1],\n",
    "            \"nodata_val\": 0,\n",
    "            \"nodata_color\": \"#ffffff00\",\n",
    "            \"palette\": [\"#d9c43f\", \"#d93fce\"]\n",
    "        }\n",
    "    ],\n",
    "    \"deduplicate_at\": [\"staging\"],\n",
    "    \"deduplicate_method\": \"neighbor\",\n",
    "    \"deduplicate_keep_rules\": [[\"staging_filename\", \"larger\"]],\n",
    "    \"deduplicate_overlap_tolerance\": 0.1,\n",
    "    \"deduplicate_overlap_both\": false,\n",
    "    \"deduplicate_centroid_tolerance\": null\n",
    "  }\n",
    "  ```\n",
    "\n",
    "### Python Environment\n",
    "\n",
    "Using jcohen's virtual env `pdgWorkflow` with `parsl` and updated `pdgstaging` & `pdgraster` as of 12/5/22.\n",
    "\n",
    "Packages & versions used for this workflow:\n",
    "\n",
    "```\n",
    "Package            Version\n",
    "------------------ ----------\n",
    "affine             2.3.1\n",
    "asttokens          2.0.5\n",
    "attrs              22.1.0\n",
    "backcall           0.2.0\n",
    "bcrypt             4.0.1\n",
    "certifi            2022.9.24\n",
    "cffi               1.15.1\n",
    "charset-normalizer 2.1.1\n",
    "click              8.1.3\n",
    "click-plugins      1.1.1\n",
    "cligj              0.7.2\n",
    "coloraide          0.18.1\n",
    "colormaps          0.3\n",
    "contourpy          1.0.6\n",
    "cryptography       38.0.4\n",
    "cycler             0.11.0\n",
    "debugpy            1.5.1\n",
    "decorator          5.1.1\n",
    "dill               0.3.6\n",
    "entrypoints        0.4\n",
    "executing          0.8.3\n",
    "filelock           3.8.2\n",
    "Fiona              1.8.22\n",
    "fonttools          4.38.0\n",
    "geopandas          0.12.1\n",
    "globus-sdk         3.15.0\n",
    "idna               3.4\n",
    "ipykernel          6.15.2\n",
    "ipython            8.6.0\n",
    "jedi               0.18.1\n",
    "jupyter_client     7.4.7\n",
    "jupyter_core       4.11.2\n",
    "kiwisolver         1.4.4\n",
    "matplotlib         3.6.2\n",
    "matplotlib-inline  0.1.6\n",
    "morecantile        3.2.2\n",
    "munch              2.5.0\n",
    "nest-asyncio       1.5.5\n",
    "numpy              1.23.5\n",
    "packaging          21.3\n",
    "pandas             1.5.2\n",
    "paramiko           2.12.0\n",
    "parsl              2022.11.28\n",
    "parso              0.8.3\n",
    "pdgraster          0.1.0\n",
    "pdgstaging         0.1.0\n",
    "pexpect            4.8.0\n",
    "pickleshare        0.7.5\n",
    "Pillow             9.3.0\n",
    "pip                22.2.2\n",
    "prompt-toolkit     3.0.20\n",
    "psutil             5.9.4\n",
    "ptyprocess         0.7.0\n",
    "pure-eval          0.2.2\n",
    "pycparser          2.21\n",
    "pydantic           1.10.2\n",
    "Pygments           2.11.2\n",
    "PyJWT              2.6.0\n",
    "PyNaCl             1.5.0\n",
    "pyparsing          3.0.9\n",
    "pyproj             3.4.0\n",
    "python-dateutil    2.8.2\n",
    "pytz               2022.6\n",
    "pyzmq              24.0.1\n",
    "rasterio           1.3.4\n",
    "requests           2.28.1\n",
    "Rtree              0.9.7\n",
    "setproctitle       1.3.2\n",
    "setuptools         65.5.0\n",
    "shapely            2.0rc2\n",
    "six                1.16.0\n",
    "snuggs             1.4.7\n",
    "stack-data         0.2.0\n",
    "tblib              1.7.0\n",
    "tornado            6.2\n",
    "traitlets          5.1.1\n",
    "typeguard          2.13.3\n",
    "typing_extensions  4.4.0\n",
    "urllib3            1.26.13\n",
    "wcwidth            0.2.5\n",
    "wheel              0.37.1\n",
    "```\n",
    "\n",
    "For problem file exploration during rasterization, uninstalled `pdgraster` and installed package with local edits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake change sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/pdg/data/nitze_lake_change/data_sample_2022-09-09/32609/05_Lake_Dataset_Raster_02_final/lake_change.gpkg',\n",
       " '/home/pdg/data/nitze_lake_change/data_sample_2022-09-09/32608/05_Lake_Dataset_Raster_02_final/lake_change.gpkg',\n",
       " '/home/pdg/data/nitze_lake_change/data_sample_2022-09-09/32607/05_Lake_Dataset_Raster_02_final/lake_change.gpkg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path('/home/pdg/data/nitze_lake_change/data_sample_2022-09-09')\n",
    "#subdirs = ['32607', '32608', '32609']\n",
    "filename = 'lake_change.gpkg'\n",
    "#to define each .gpkg file within each UTM subdir as a string representation with forward slashes, use as_posix() for each iteration\n",
    "#of base_dir + filename. The ** represents that any subdir string can be present between the base_dir and the filename\n",
    "data_paths = [p.as_posix() for p in base_dir.glob('**/' + filename)]\n",
    "data_paths\n",
    "\n",
    "# smallest data sample for troubleshooting, 2 gpkg files with spatial overlap:\n",
    "# file1 = '/home/thiessenbock/PDG-test/minimal-example/input/file1.gpkg'\n",
    "# file2 = '/home/thiessenbock/PDG-test/minimal-example/input/file2.gpkg'\n",
    "# data_paths = [file1, file2]\n",
    "# data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_config = '/home/jcohen/viz-workflow/workflow_troubleshooting/ingmar_config.json'\n",
    "\n",
    "# logging setup\n",
    "logging_config = '/home/jcohen/viz-workflow/workflow_troubleshooting/logging.json'\n",
    "\n",
    "def setup_logging(log_json_file):\n",
    "    \"\"\"\n",
    "    Setup logging configuration\n",
    "    \"\"\"\n",
    "    with open(log_json_file, 'r') as f:\n",
    "        logging_dict = json.load(f)\n",
    "    logging.config.dictConfig(logging_dict)\n",
    "    return logging_dict\n",
    "\n",
    "logging_dict = setup_logging(logging_config)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StagedTo3DConverter():\n",
    "    \"\"\"\n",
    "        Processes staged vector data into Cesium 3D tiles according to the\n",
    "        settings in a config file or dict. This class acts as the orchestrator\n",
    "        of the other viz-3dtiles classes, and coordinates the sending and\n",
    "        receiving of information between them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Automatically initialize the StagedTo3DConverter class by appying the configuration when an object of that class is created.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            self : need to explicitly state this parameter to pass any newly created object of class StagedTo3DConverter to the other paraneter (config)\n",
    "                this is a python syntax requirement in order for the object to persist of this class\n",
    "\n",
    "            config : dict or str\n",
    "                A dictionary of configuration settings or a path to a config\n",
    "                JSON file. (See help(pdgstaging.ConfigManager))\n",
    "\n",
    "            Notes\n",
    "            ----------\n",
    "            - this function does not do the staging or tiling steps\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = pdgstaging.ConfigManager(config)\n",
    "        self.tiles = pdgstaging.TilePathManager(\n",
    "            **self.config.get_path_manager_config())\n",
    "\n",
    "    def all_staged_to_3dtiles(\n",
    "        self\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Process all staged vector tiles into 3D tiles. This is simply a loop that iterates the function staged_to_rdtile() over all files in the staged directory.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the list of staged vector tiles\n",
    "        paths = self.tiles.get_filenames_from_dir('staged')\n",
    "        # Process each tile\n",
    "        for path in paths:\n",
    "            self.staged_to_3dtile(path)\n",
    "\n",
    "    def staged_to_3dtile(self, path):\n",
    "        \"\"\"\n",
    "            Convert a staged vector tile into a B3DM tile file and a matching\n",
    "            JSON tileset file.\n",
    "            - the B3DM tile is applied to the PDG portal for visualization purposes\n",
    "            - the JSON serves as the metadata for that tile\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            path : str\n",
    "                The path to the staged vector tile.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            tile, tileset : Cesium3DTile, Tileset\n",
    "                The Cesium3DTiles and Cesium3DTileset objects\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            \n",
    "            # Get information about the tile from the path\n",
    "            tile = self.tiles.tile_from_path(path)\n",
    "            out_path = self.tiles.path_from_tile(tile, '3dtiles')\n",
    "\n",
    "            tile_bv = self.bounding_region_for_tile(tile) # bv = bounding volumne\n",
    "\n",
    "            # Get the filename of the tile WITHOUT the extension\n",
    "            tile_filename = os.path.splitext(os.path.basename(out_path))[0]\n",
    "            # Get the base of the path, without the filename\n",
    "            tile_dir = os.path.dirname(out_path) + os.path.sep\n",
    "\n",
    "            # Log the event\n",
    "            logger.info(\n",
    "                f'Creating 3dtile from {path} for tile {tile} to {out_path}.')\n",
    "\n",
    "            # Read in the staged vector tile\n",
    "            gdf = gpd.read_file(path)\n",
    "\n",
    "            # Summary of following steps:\n",
    "            # Now that we have the path to the staged vector tile esptablished and logged, \n",
    "            # the following checks are executed on each staged vector tile:\n",
    "            # 1. check if the tile has any data to start with\n",
    "            # 2. check if the centroid of the polygons within the tile are within the tile boundaries, remove if not\n",
    "            # 3. check if polygons within the tile overlap, deduplicate them if they do\n",
    "            # 4. check if the tile has any data left if deduplication was executed\n",
    "            # 5. if there were errors in the above steps, log that for debugging\n",
    "\n",
    "            \n",
    "            # Check if the gdf is empty\n",
    "            if len(gdf) == 0:\n",
    "                logger.warning(\n",
    "                    f'Vector tile {path} is empty. 3D tile will not be'\n",
    "                    ' created.')\n",
    "                return\n",
    "\n",
    "            # Remove polygons with centroids that are outside the tile boundary\n",
    "            prop_cent_in_tile = self.config.polygon_prop(\n",
    "                'centroid_within_tile')\n",
    "            gdf = gdf[gdf[prop_cent_in_tile]]\n",
    "\n",
    "            # Check if deduplication should be performed\n",
    "            dedup_here = self.config.deduplicate_at('3dtiles')\n",
    "            dedup_method = self.config.get_deduplication_method()\n",
    "\n",
    "            # Deduplicate if required\n",
    "            if dedup_here and (dedup_method is not None):\n",
    "                dedup_config = self.config.get_deduplication_config(gdf)\n",
    "                dedup = dedup_method(gdf, **dedup_config)\n",
    "                gdf = dedup['keep']\n",
    "\n",
    "                # The tile could theoretically be empty after deduplication\n",
    "                if len(gdf) == 0:\n",
    "                    logger.warning(\n",
    "                        f'Vector tile {path} is empty after deduplication.'\n",
    "                        ' 3D Tile will not be created.')\n",
    "                    return\n",
    "\n",
    "            # Create & save the b3dm file\n",
    "            ces_tile, ces_tileset = TreeGenerator.leaf_tile_from_gdf(\n",
    "                gdf,\n",
    "                dir=tile_dir,\n",
    "                filename=tile_filename,\n",
    "                z=self.config.get('z_coord'),\n",
    "                geometricError=self.config.get('geometricError'),\n",
    "                tilesetVersion=self.config.get('version'),\n",
    "                boundingVolume=tile_bv\n",
    "            )\n",
    "\n",
    "            return ces_tile, ces_tileset\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error creating 3D Tile from {path}.')\n",
    "            logger.error(e)\n",
    "\n",
    "    def parent_3dtiles_from_children(self, tiles, bv_limit=None):\n",
    "        \"\"\"\n",
    "            Create parent Cesium 3D Tileset json files that point to\n",
    "            of child JSON files in the tile tree hierarchy.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            tiles : list of morecantile.Tile\n",
    "                The list of tiles to create parent tiles for.\n",
    "        \"\"\"\n",
    "\n",
    "        tile_manager = self.tiles\n",
    "        config_manager = self.config\n",
    "\n",
    "        tileset_objs = []\n",
    "\n",
    "        # Make the next level of parent tiles\n",
    "        for parent_tile in tiles:\n",
    "            # Get the path to the parent tile\n",
    "            parent_path = tile_manager.path_from_tile(parent_tile, '3dtiles')\n",
    "            # Get just the base dir without the filename\n",
    "            parent_dir = os.path.dirname(parent_path)\n",
    "            # Get the filename of the parent tile, without the extension\n",
    "            parent_filename = os.path.basename(parent_path)\n",
    "            parent_filename = os.path.splitext(parent_filename)[0]\n",
    "            # Get the children paths for this parent tile\n",
    "            child_paths = tile_manager.get_child_paths(parent_tile, '3dtiles')\n",
    "            # Remove paths that do not exist\n",
    "            child_paths = tile_manager.remove_nonexistent_paths(child_paths)\n",
    "            # Get the parent bounding volume\n",
    "            parent_bv = self.bounding_region_for_tile(\n",
    "                parent_tile, limit_to=bv_limit)\n",
    "            # If the bounding region is outside t\n",
    "            # Get the version\n",
    "            version = config_manager.get('version')\n",
    "            # Get the geometric error\n",
    "            geometric_error = config_manager.get('geometricError')\n",
    "            # Create the parent tile\n",
    "            tileset_obj = TreeGenerator.parent_tile_from_children_json(\n",
    "                child_paths,\n",
    "                dir=parent_dir,\n",
    "                filename=parent_filename,\n",
    "                geometricError=geometric_error,\n",
    "                tilesetVersion=version,\n",
    "                boundingVolume=parent_bv\n",
    "            )\n",
    "            tileset_objs.append(tileset_obj)\n",
    "\n",
    "        return tileset_objs\n",
    "\n",
    "    def bounding_region_for_tile(self, tile, limit_to=None):\n",
    "        \"\"\"\n",
    "        For a morecantile.Tile object, return a BoundingVolumeRegion object\n",
    "        that represents the bounding region of the tile.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tile : morecantile.Tile\n",
    "            The tile object.\n",
    "        limit_to : list of float\n",
    "            Optional list of west, south, east, north coordinates to limit\n",
    "            the bounding region to.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bv : BoundingVolumeRegion\n",
    "            The bounding region object.\n",
    "        \"\"\"\n",
    "        tms = self.tiles.tms\n",
    "        bounds = tms.bounds(tile)\n",
    "        bounds = gpd.GeoSeries(\n",
    "            box(bounds.left, bounds.bottom, bounds.right, bounds.top),\n",
    "            crs=tms.crs)\n",
    "        if limit_to is not None:\n",
    "            bounds_limitor = gpd.GeoSeries(\n",
    "                box(limit_to[0], limit_to[1], limit_to[2], limit_to[3]),\n",
    "                crs=tms.crs)\n",
    "            bounds = bounds.intersection(bounds_limitor)\n",
    "        bounds = bounds.to_crs(BoundingVolumeRegion.CESIUM_EPSG)\n",
    "        bounds = bounds.total_bounds\n",
    "\n",
    "        region_bv = {\n",
    "            'west': bounds[0], 'south': bounds[1],\n",
    "            'east': bounds[2], 'north': bounds[3],\n",
    "        }\n",
    "        return region_bv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration files and creating stager, rasterizer, and tilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staging configuration\n",
    "stager = pdgstaging.TileStager(workflow_config)\n",
    "tile_manager = stager.tiles\n",
    "config_manager = stager.config\n",
    "\n",
    "# zoom levels configuration\n",
    "min_z = config_manager.get_min_z()\n",
    "max_z = config_manager.get_max_z()\n",
    "parent_zs = range(max_z - 1, min_z - 1, -1)\n",
    "\n",
    "# 3D tiler configuration\n",
    "tiles3dmaker = StagedTo3DConverter(workflow_config)\n",
    "\n",
    "# raster tilerconfiguration \n",
    "#rasterizer = pdgraster.RasterTiler(workflow_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsl setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f8950089af0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bash command to activate virtual environment\n",
    "activate_env = 'source /home/jcohen/.bashrc; conda activate pdgWorkflow'\n",
    "\n",
    "htex_config_local = Config(\n",
    "  executors = [\n",
    "      HighThroughputExecutor(\n",
    "        label = \"htex_Local\",\n",
    "        cores_per_worker = 2, \n",
    "        max_workers = 2, # why would this be so low? because just testing with small amount of data ?\n",
    "          # worker_logdir_root = '/' only necessary if the file system is remote, which is not the case for this lake change sample\n",
    "          # address not necessary because we are not using kubernetes\n",
    "        worker_debug = False, # don't need this because we have logging setup\n",
    "          # provider is local for this run thru, kubernetes would use KubernetesProvider()\n",
    "        provider = LocalProvider(\n",
    "          channel = LocalChannel(),\n",
    "          worker_init = activate_env,\n",
    "          init_blocks = 1, # default I think\n",
    "          max_blocks = 10 # changed from deafult of 1\n",
    "        ),\n",
    "      )\n",
    "    ],\n",
    "  )\n",
    "\n",
    "parsl.clear() # first clear the current configuration since we will likely run this script multiple times\n",
    "parsl.load(htex_config_local) # load the config we just outlined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_staging=1 # change this depending on data sample size!!!!!\n",
    "batch_size_rasterization=30\n",
    "batch_size_3dtiles=20\n",
    "batch_size_parent_3dtiles=500\n",
    "batch_size_geotiffs=200\n",
    "batch_size_web_tiles=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(items, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches of a given size from a list of items.\n",
    "    \"\"\"\n",
    "    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_batches = make_batch(data_paths, batch_size_staging)\n",
    "#input_batches # 3 batches, 1 file each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decorators seem to be ignored as the first line of a cell, so print something first\n",
    "# print(\"Stage in parallel\")\n",
    "\n",
    "# @python_app\n",
    "# def stage(paths, config, logging_dict = logging_dict): \n",
    "#     \"\"\"\n",
    "#     Stage files (step 1)\n",
    "#     \"\"\"\n",
    "#     import pdgstaging\n",
    "#     if logging_dict:\n",
    "#         import logging.config\n",
    "#         logging.config.dictConfig(logging_dict)\n",
    "#     stager = pdgstaging.TileStager(config)\n",
    "#     for path in paths:\n",
    "#         stager.stage(path)\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_futures = []\n",
    "# for batch in input_batches:\n",
    "#     app_future = stage(batch, workflow_config, logging_dict)\n",
    "#     app_futures.append(app_future)\n",
    "\n",
    "# [a.result() for a in app_futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# htex_config_local.executors[0].shutdown()\n",
    "# parsl.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to all the newly staged tiles\n",
    "staged_paths = stager.tiles.get_filenames_from_dir('staged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(staged_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch staged files\n",
    "staged_batches = make_batch(staged_paths, batch_size_rasterization)\n",
    "len(staged_batches) # 637 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what is within 1 batch\n",
    "# staged_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasterize in parallel\n"
     ]
    }
   ],
   "source": [
    "print('rasterize in parallel')\n",
    "\n",
    "@python_app\n",
    "def rasterize(staged_paths, config, logging_dict = logging_dict):\n",
    "    \"\"\"\n",
    "    Rasterize a batch of vector files (step 2)\n",
    "    \"\"\"\n",
    "    import pdgraster\n",
    "    if logging_dict:\n",
    "        import logging.config\n",
    "        logging.config.dictConfig(logging_dict)\n",
    "    rasterizer = pdgraster.RasterTiler(config)\n",
    "    return rasterizer.rasterize_vectors(staged_paths, make_parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_futures = []\n",
    "for batch in staged_batches:\n",
    "    app_future = rasterize(batch, workflow_config, logging_dict)\n",
    "    app_futures.append(app_future)\n",
    "\n",
    "# Don't continue to step 3 until all tiles have been rasterized\n",
    "[a.result() for a in app_futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "htex_config_local.executors[0].shutdown()\n",
    "parsl.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staged file paths = 19088, geotiff z-level 11 = 19085, 3 missing\n",
    "# get raster file paths from z-level 11 to compare to staged file paths\n",
    "\n",
    "# start with all z-levels because the input to this function needs to be base dir\n",
    "geotiff_paths = tile_manager.get_filenames_from_dir('geotiff')\n",
    "\n",
    "# remove strings that do not have z-level 11\n",
    "geotiff_paths_11 = []\n",
    "for path in geotiff_paths:\n",
    "    if '1' == path[21:22]:\n",
    "        geotiff_paths_11.append(path)\n",
    "\n",
    "#geotiff_paths_11\n",
    "\n",
    "# remove leading dir 'geotiff'\n",
    "geotiff_paths_11_trimmed = []\n",
    "for path in geotiff_paths_11:\n",
    "    trimmed_1 = path.replace('geotiff', '')\n",
    "    trimmed_2 = trimmed_1.replace('.tif', '')\n",
    "    geotiff_paths_11_trimmed.append(trimmed_2)\n",
    "\n",
    "geotiff_paths_11_trimmed[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staged_paths = stager.tiles.get_filenames_from_dir('staged')\n",
    "\n",
    "# remove 'staged' and 'gpkg'\n",
    "staged_paths_trimmed = []\n",
    "for path in staged_paths:\n",
    "    trimmed_1 = path.replace('staged', '')\n",
    "    trimmed_2 = trimmed_1.replace('.gpkg', '')\n",
    "    staged_paths_trimmed.append(trimmed_2)\n",
    "\n",
    "staged_paths_trimmed[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract lists of file paths\n",
    "missing_files = []\n",
    "for path in staged_paths_trimmed:\n",
    "  if path not in geotiff_paths_11_trimmed:\n",
    "    missing_files.append(path)\n",
    "\n",
    "missing_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterize problematic files on their own with modified viz-staging (edited locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'staged'\n",
    "ext = '.gpkg'\n",
    "problem_file_1 = base_dir + '/WGS1984Quad/11/557/256' + ext\n",
    "problem_file_2 = base_dir + '/WGS1984Quad/11/463/320' + ext\n",
    "problem_file_3 = base_dir + '/WGS1984Quad/11/463/253' + ext\n",
    "\n",
    "# make into list\n",
    "prob_files = [problem_file_1, problem_file_2, problem_file_3]\n",
    "\n",
    "# make batches (1 file per batch)\n",
    "prob_batches = make_batch(prob_files, 1)\n",
    "prob_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_futures = []\n",
    "for batch in prob_batches:\n",
    "    app_future = rasterize(batch, workflow_config, logging_dict)\n",
    "    app_futures.append(app_future)\n",
    "\n",
    "# Don't continue to step 3 until all tiles have been rasterized\n",
    "[a.result() for a in app_futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the following:\n",
    "\n",
    "1. number of rasters in z-level 11 compared to number of staged files (which are all z-level 11)\n",
    "2. number of rasters in all z-levels matches number of rasters in all z-levels from other run-through not in parallel (lake_change_sample dir)\n",
    "3. any weird formatting in rasters_summary.csv? fix if so\n",
    "4. any errors reported in rasterization_events.csv?\n",
    "4. any errors reported in log.log?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Web Tiles from geoTIFF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update ranges from raster_summary.csv\n",
    "# rasterizer.update_ranges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process web tiles in batches\n",
    "# geotiff_batches = make_batch(geotiff_paths, batch_size_web_tiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pdgWorkflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7623f3618ad68fbee5037a6e6034c21563de9153501ce39b7d33b02786db05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
